{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7wL9gCqTSZ4hCfbLublPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiragGadhvi/DLNLP-LAB/blob/main/tfidfvectorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference Link: [Theroy](https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3)\n",
        "\n",
        "Youtube Link: [Youtube](https://www.youtube.com/watch?v=ouEVPRMHR1U)"
      ],
      "metadata": {
        "id": "RLr4OWInrwtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer simply counts the number of times a word appears in a document (using a bag-of-words approach), while TF-IDF Vectorizer takes into account not only how many times a word appears in a document but also how important that word is to the whole corpus."
      ],
      "metadata": {
        "id": "U7gPO2twpyWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Term Frequency Inverse Document Frequency (TFIDF) analysis is one of the simple and robust methods to understand the context of a text. Term Frequency and Inverse Document Frequency is used to find the related content and important words and phrases in a larger text."
      ],
      "metadata": {
        "id": "B1s7ABuMqBHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF is useful in solving the major drawbacks of Bag of words by introducing an important concept called inverse document frequency.\n",
        "\n",
        "It’s a score which the machine keeps where it is evaluates the words used in a sentence and measures it’s usage compared to words used in the entire document. In other words, it’s a score to highlight each word’s relevance in the entire document."
      ],
      "metadata": {
        "id": "VjLzDhItqrZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDF =Log[(# Number of documents) / (Number of documents containing the word)] and\n",
        "\n",
        "TF = (Number of repetitions of word in a document) / (# of words in a document)"
      ],
      "metadata": {
        "id": "7bK7c9GrqxKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1 Declaring all documents and assigning to a Vocab document"
      ],
      "metadata": {
        "id": "gXTcy8ePvGJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQW6pskOmB0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891d7c04-fa7f-41a1-deef-19a5f534e286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It is going to rain today.', 'Today I am not going outside.', 'I am going to watch the season premiere.']\n"
          ]
        }
      ],
      "source": [
        "Document1= \"It is going to rain today.\"\n",
        "Document2= \"Today I am not going outside.\"\n",
        "Document3= \"I am going to watch the season premiere.\"\n",
        "Doc = [Document1 ,\n",
        "       Document2 ,\n",
        "       Document3]\n",
        "print(Doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2 —intializing TFIDFVectorizer"
      ],
      "metadata": {
        "id": "Bf6ozcogvk2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "DqP0X5WevmGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 3 — Getting feature names of final words that we will use to tag documents"
      ],
      "metadata": {
        "id": "Z0b-quGCwBCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(Doc)"
      ],
      "metadata": {
        "id": "fpG7smUQylfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze = vectorizer.build_analyzer()\n",
        "print('Document 1',analyze(Document1))\n",
        "print('Document 2',analyze(Document2))\n",
        "print('Document 3',analyze(Document3))\n",
        "print('Document transform',X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGWqcd9Uvq-X",
        "outputId": "c05a8304-72e6-47a7-8c7d-1d692bad2da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1 ['it', 'is', 'going', 'to', 'rain', 'today']\n",
            "Document 2 ['today', 'am', 'not', 'going', 'outside']\n",
            "Document 3 ['am', 'going', 'to', 'watch', 'the', 'season', 'premiere']\n",
            "Document transform [[0.         0.27824521 0.4711101  0.4711101  0.         0.\n",
            "  0.         0.4711101  0.         0.         0.35829137 0.35829137\n",
            "  0.        ]\n",
            " [0.40619178 0.31544415 0.         0.         0.53409337 0.53409337\n",
            "  0.         0.         0.         0.         0.         0.40619178\n",
            "  0.        ]\n",
            " [0.32412354 0.25171084 0.         0.         0.         0.\n",
            "  0.4261835  0.         0.4261835  0.4261835  0.32412354 0.\n",
            "  0.4261835 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(Doc)\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc_9GR6HyEzh",
        "outputId": "6cae43c9-d6e9-423b-8cd1-731b883529f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['am' 'going' 'is' 'it' 'not' 'outside' 'premiere' 'rain' 'season' 'the'\n",
            " 'to' 'today' 'watch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.max(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ohKlO0r16ls",
        "outputId": "c5e74f46-6836-47f2-d809-a89cdcf78934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5340933749435834\n"
          ]
        }
      ]
    }
  ]
}